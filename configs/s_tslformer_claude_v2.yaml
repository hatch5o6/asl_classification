# TSLFormer-inspired configuration for skeleton-only ASL classification
# v2: Fixed joint pruning with warmup period and better initialization
#
# Key changes from v1:
# 1. init_keep_probability: 0.9 (start with all joints, learn to prune)
# 2. l0_warmup_steps: 5000 (let model learn which joints matter BEFORE applying L0)
# 3. l0_weight: 0.0001 (reduced from 0.001 for gentler pruning pressure)

save: /home/hatch5o6/groups/grp_asl_classification/nobackup/archive/SLR/models/s_tslformer_claude_v2
test_checkpoint: null
modalities: ["skeleton"]
joint_pruning: True

train_csv: data/train.csv
val_csv: data/val.csv
test_csv: data/test.csv
class_id_csv: data/SignList_ClassId_TR_EN.csv

seed: 4000

n_gpus: 4
device: cuda

# Learning rates
pretrained_learning_rate: 5e-05
new_learning_rate: 1e-04
skel_learning_rate: 1e-04
class_learning_rate: 1e-04
weight_decay: 0.01

# Training schedule
effective_batch_size: 32
early_stop: 10
save_top_k: 10
val_interval: 0.25
max_steps: 200000

# Architecture - TSLFormer-inspired
fusion_dim: 512
depth_image_size: 224
depth_hidden_dim: 384
depth_hidden_layers: 6
depth_att_heads: 6
depth_intermediate_size: 1536
depth_patch_size: 16

# BERT Skeleton Encoder
bert_hidden_layers: 2
bert_hidden_dim: 512
bert_att_heads: 8
bert_intermediate_size: 2048

# Joint pruning configuration - FIXED
num_pose_points: 543
init_keep_probability: 0.9  # Start high, learn to prune (not 0.5!)
l0_warmup_steps: 5000  # NEW: No L0 penalty for first 5000 steps
l0_weight: 0.0001  # NEW: Reduced from 0.001 for gentler pruning
classifier_dropout: 0.2

gradient_clip_val: 1.0

# v2 fixes:
# - Higher init_keep_prob (0.9): All joints start "on", model learns which to prune
# - L0 warmup: Model first learns which joints are useful for classification
#              THEN L0 penalty kicks in to prune the unimportant ones
# - Lower L0 weight: Gentler pressure so important joints can fight back
